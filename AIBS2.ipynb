{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RS_pop[0]/v'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os, sys\n",
    "#print('forcing load of development neuron unit')\n",
    "#sys.path[0]='/home/jovyan/work/scidash'\n",
    "#sys.path[-1]='/home/jovyan/work/scidash'\n",
    "#print(sys.path)\n",
    "#import neuronunit\n",
    "#print(neuronunit.__file__)\n",
    "#import pdb\n",
    "#pdb.set_trace()\n",
    "\n",
    "\n",
    "def use_dev_packages(dev_packages):\n",
    "    \"\"\"\n",
    "    Adapted from Rickpy https://github.com/rgerkin/rickpy \n",
    "    Prepends items in dev_packages to sys.path, and \n",
    "    assumes these paths exist in the \n",
    "    the user's HOME/mnt/sciunitopt/ directory. \n",
    "    Format for dev_packages items is repo/package.\n",
    "    \n",
    "    /home/jovyan\n",
    "    \"\"\"\n",
    "\n",
    "    HOME = os.path.expanduser('~')\n",
    "    \n",
    "    sp = os.path.join('/','opt/conda/lib/python3.5/site-packages')\n",
    "    if os.path.exists(sp) and sp not in sys.path:\n",
    "        sys.path.append(sp)  \n",
    "    for i,package in enumerate(dev_packages):\n",
    "        if package.split('/')[-1] not in sys.path[len(dev_packages)-i]:\n",
    "            sys.path.insert(1,os.path.join(HOME,'mnt/sciunitopt/',package))  \n",
    "\n",
    "#use_dev_packages([neuronunit])\n",
    "path=os.getcwd()\n",
    "\n",
    "'RS_pop[0]/v'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n",
      "/opt/conda/lib/python3.5/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attempting to recover from pickled file\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# In[2]:\n",
    "#get_ipython().magic('matplotlib notebook')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import quantities as pq\n",
    "import sciunit\n",
    "import neuronunit\n",
    "#from neuronunit import aibs\n",
    "import pickle as pickle\n",
    "import pdb\n",
    "\n",
    "from neuronunit.models.reduced import ReducedModel\n",
    "\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "# Replace this with your model path.  \n",
    "# This example is from https://github.com/OpenSourceBrain/IzhikevichModel.\n",
    "HOME = os.path.expanduser('~')\n",
    "LEMS_MODEL_PATH = os.path.join(os.getcwd(),'LEMS_2007One.xml')\n",
    "model = ReducedModel(LEMS_MODEL_PATH,name='vanilla')\n",
    "\n",
    "\n",
    "\n",
    "#print(LEMS_MODEL_PATH)\n",
    "\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "#vm=np.zeros(13)\n",
    "from neuronunit.capabilities import spike_functions\n",
    "#waveforms = spike_functions.get_spike_waveforms(vm)\n",
    "#np.max(waveforms.data,axis=1)\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "#np.max(np.array(waveforms),axis=1)\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "#np.max(waveforms,axis=1)\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "import quantities as pq\n",
    "from neuronunit import tests as nu_tests, neuroelectro\n",
    "neuron = {'nlex_id': 'nifext_50'} # Layer V pyramidal cell\n",
    "\n",
    "tests = []\n",
    "\n",
    "dataset_id = 354190013  # Internal ID that AIBS uses for a particular Scnn1a-Tg2-Cre \n",
    "                        # Primary visual area, layer 5 neuron.\n",
    "#observation = aibs.get_observation(dataset_id,'rheobase')\n",
    "from allensdk.api.queries.cell_types_api import CellTypesApi\n",
    "from allensdk.ephys.extract_cell_features import get_square_stim_characteristics,\\\n",
    "                                                 get_sweep_from_nwb\n",
    "from allensdk.core import nwb_data_set\n",
    "\n",
    "ct = CellTypesApi()\n",
    "\n",
    "def get_sp(experiment_params,sweep_ids):\n",
    "    '''\n",
    "    get sweep parameter\n",
    "    TODO: move method into neuronunit/aibs.py, as this is a fix for that file.    \n",
    "    '''\n",
    "    sweep_num = None\n",
    "    for sp in experiment_params:\n",
    "       for i in sweep_ids:\n",
    "          if sp['id']==i:\n",
    "              sweep_num = sp['sweep_number']\n",
    "              found_sp=sp\n",
    "              break\n",
    "    if sweep_num is None:\n",
    "        found_sp=None          \n",
    "        raise Exception('Sweep with ID %d not found in dataset with ID %d.' % (sweep_id, dataset_id))\n",
    "    return found_sp\n",
    "\n",
    "\n",
    "def get_value_dict(experiment_params,sweep_ids,kind=str('rheobase')):\n",
    "    '''\n",
    "    return values\n",
    "    TODO: move method into neuronunit/aibs.py, as this is a fix for that file.\n",
    "    '''\n",
    "    if kind == str('rheobase'):\n",
    "        sp=get_sp(experiment_params,sweep_ids)\n",
    "        value = sp['stimulus_absolute_amplitude']\n",
    "        value = np.round(value,2) # Round to nearest hundredth of a pA.\n",
    "        value *= pq.pA # Apply units.  \n",
    "\n",
    "        #Need some way to sanitize values in the dictionary below:.\n",
    "        return {'value': value}              \n",
    "              \n",
    "\n",
    "\n",
    "#save some time by pickle loading the content if its available. \n",
    "#using allensdk cache would be preferable, but I don't yet understand the syntax.\n",
    "\n",
    "\n",
    "if os.path.exists(str(os.getcwd())+\"/observations.pickle\"):\n",
    "    print('attempting to recover from pickled file')\n",
    "    with open('observations.pickle', 'rb') as handle:\n",
    "        observation = pickle.load(handle)\n",
    "\n",
    "else:\n",
    "    print('checked path:')\n",
    "    print(str(os.getcwd())+\"/observation.pickle\")\n",
    "    print('no pickled file down loading time intensive')\n",
    "    experiment_params = ct.get_ephys_sweeps(dataset_id)\n",
    "    cmd = ct.get_ephys_features(dataset_id)\n",
    "    sweep_ids=cmd['rheobase_sweep_id'] #Retrieva all of the sweeps corresponding to finding rheobase.\n",
    "    observation=get_value_dict(experiment_params,sweep_ids)\n",
    "    with open('observations.pickle', 'wb') as handle:\n",
    "        pickle.dump(observation, handle)\n",
    "\n",
    "\n",
    "#Compare differences between Allen Brain derived observations, Neuroelectro derived recordings and \n",
    "#Izkevitch model\n",
    "\n",
    "\n",
    "\n",
    "tests += [nu_tests.RheobaseTest(observation=observation)]\n",
    "#Edited out below:   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuronunit_generated these tests\n",
      "neuronunit_generated these tests\n",
      "Getting data values from neuroelectro.org\n",
      "http://www.neuroelectro.org/api/1/nes/?nlex=nifext_50&e__name=Input+Resistance\n",
      "{'mean': array(120672073.643411) * ohm, 'std': array(77633160.8333564) * ohm, 'n': {'name': 'Neocortex pyramidal cell layer 5-6', 'id': 111, 'neuron_db_id': 265, 'nlex_id': 'nifext_50'}}\n",
      "[Rheobase test, Input resistance test]\n",
      "<class 'neuronunit.tests.InputResistanceTest'> None\n",
      "neuronunit_generated these tests\n",
      "Getting data values from neuroelectro.org\n",
      "http://www.neuroelectro.org/api/1/nes/?nlex=nifext_50&e__name=Membrane+Time+Constant\n",
      "{'mean': array(15.7342424242424) * ms, 'std': array(7.31162636832495) * ms, 'n': {'name': 'Neocortex pyramidal cell layer 5-6', 'id': 111, 'neuron_db_id': 265, 'nlex_id': 'nifext_50'}}\n",
      "[Rheobase test, Input resistance test, Time constant test]\n",
      "<class 'neuronunit.tests.TimeConstantTest'> None\n",
      "neuronunit_generated these tests\n",
      "Getting data values from neuroelectro.org\n",
      "http://www.neuroelectro.org/api/1/nes/?nlex=nifext_50&e__name=Cell+Capacitance\n",
      "{'mean': array(1.50584166666667e-10) * F, 'std': array(1.39683884626343e-10) * F, 'n': {'name': 'Neocortex pyramidal cell layer 5-6', 'id': 111, 'neuron_db_id': 265, 'nlex_id': 'nifext_50'}}\n",
      "[Rheobase test, Input resistance test, Time constant test, Capacitance test]\n",
      "<class 'neuronunit.tests.CapacitanceTest'> None\n",
      "[Rheobase test, Input resistance test, Time constant test, Capacitance test]\n",
      "{Rheobase test: {'f': <function update_amplitude at 0x7f19ec991d08>}}\n",
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'description', 'from_observations', 'include_models', 'judge', 'name', 'set_verbose', 'skip_models', 'tests']\n",
      "interesting that the basic model works\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Executing test <i>Rheobase test</i> on model <i>vanilla</i>... "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyNeuroML >>> Executing: (java -Xmx400M  -Djava.awt.headless=true -jar  \"/opt/conda/lib/python3.5/site-packages/pyneuroml/lib/jNeuroML-0.8.0-jar-with-dependencies.jar\"  \"/tmp/vanilla.xml\"  -neuron -run -nogui) in directory: .\n",
      "pyNeuroML >>> Command completed. Output: \n",
      "pyNeuroML >>>   jNeuroML >>   jNeuroML v0.8.0\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Reading from: /tmp/vanilla.xml\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Creating NeuronWriter for vanilla_nrn.py\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Adding simulation Component(id=sim1 type=Simulation) of network/component: net1 (Type: network)\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Adding population: RS_pop\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) -- Writing to mod: /tmp/RS.mod\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Adding projections/connections...\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) -- Writing to mod: /tmp/RS_Iext.mod\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Trying to compile mods in: /tmp\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Going to compile the mod files in: /tmp, forcing recompile: false\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Parent dir: /tmp\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Assuming *nix environment...\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Name of file to be created: /tmp/x86_64/libnrnmech.la\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Backup file to check for success: /tmp/x86_64/libnrnmech.la\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) commandToExecute: /home/jovyan/neuron/nrn-7.4/x86_64/bin/nrnivmodl\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Going to check if mods in /tmp are newer than null\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Trying to delete any previous: /tmp/x86_64/libnrnmech.la\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) directoryToExecuteIn: /tmp\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > Creating x86_64 directory for .o files.\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > \n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Have successfully executed command: /home/jovyan/neuron/nrn-7.4/x86_64/bin/nrnivmodl\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > /tmp\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > RS.mod RS_Iext.mod\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > RS.mod RS_Iext.mod\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > \"/home/jovyan/neuron/nrn-7.4/x86_64/bin/nocmodl\" RS\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Error   >> > Translating RS.mod into RS.c\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Error   >> > Thread Safe\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > \"/home/jovyan/neuron/nrn-7.4/share/nrn/libtool\"  --mode=compile gcc -DHAVE_CONFIG_H  -I. -I.. -I\"/home/jovyan/neuron/nrn-7.4/include/nrn\" -I\"/home/jovyan/neuron/nrn-7.4/x86_64/lib\"      -g -O2 -c -o RS.lo RS.c\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > libtool: compile:  gcc -DHAVE_CONFIG_H -I. -I.. -I/home/jovyan/neuron/nrn-7.4/include/nrn -I/home/jovyan/neuron/nrn-7.4/x86_64/lib -g -O2 -c RS.c  -fPIC -DPIC -o .libs/RS.o\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > \"/home/jovyan/neuron/nrn-7.4/x86_64/bin/nocmodl\" RS_Iext\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Error   >> > Translating RS_Iext.mod into RS_Iext.c\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Error   >> > Thread Safe\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > \"/home/jovyan/neuron/nrn-7.4/share/nrn/libtool\"  --mode=compile gcc -DHAVE_CONFIG_H  -I. -I.. -I\"/home/jovyan/neuron/nrn-7.4/include/nrn\" -I\"/home/jovyan/neuron/nrn-7.4/x86_64/lib\"      -g -O2 -c -o RS_Iext.lo RS_Iext.c\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > libtool: compile:  gcc -DHAVE_CONFIG_H -I. -I.. -I/home/jovyan/neuron/nrn-7.4/include/nrn -I/home/jovyan/neuron/nrn-7.4/x86_64/lib -g -O2 -c RS_Iext.c  -fPIC -DPIC -o .libs/RS_Iext.o\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > \"/home/jovyan/neuron/nrn-7.4/share/nrn/libtool\"  --mode=compile gcc -DHAVE_CONFIG_H  -I. -I.. -I\"/home/jovyan/neuron/nrn-7.4/include/nrn\" -I\"/home/jovyan/neuron/nrn-7.4/x86_64/lib\"      -g -O2 -c -o mod_func.lo mod_func.c\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > libtool: compile:  gcc -DHAVE_CONFIG_H -I. -I.. -I/home/jovyan/neuron/nrn-7.4/include/nrn -I/home/jovyan/neuron/nrn-7.4/x86_64/lib -g -O2 -c mod_func.c  -fPIC -DPIC -o .libs/mod_func.o\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > \"/home/jovyan/neuron/nrn-7.4/share/nrn/libtool\"  --mode=link gcc -module  -g -O2    -o libnrnmech.la -rpath \"/home/jovyan/neuron/nrn-7.4/x86_64/lib\"  RS.lo RS_Iext.lo mod_func.lo  -L\"/home/jovyan/neuron/nrn-7.4/x86_64/lib\" -lnrnoc -loc -lmemacs -lnrnmpi -lscopmath -lsparse13 -lreadline -lncurses -L\"/home/jovyan/neuron/nrn-7.4/x86_64/lib\" \"/home/jovyan/neuron/nrn-7.4/x86_64/lib/libnrniv.la\" -livoc -lneuron_gnu -lmeschach -lsundials -livos      -lm -ldl\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > libtool: link: gcc -shared  -fPIC -DPIC  .libs/RS.o .libs/RS_Iext.o .libs/mod_func.o   -Wl,-rpath -Wl,/home/jovyan/neuron/nrn-7.4/x86_64/lib -Wl,-rpath -Wl,/home/jovyan/neuron/nrn-7.4/x86_64/lib -L/home/jovyan/neuron/nrn-7.4/x86_64/lib /home/jovyan/neuron/nrn-7.4/x86_64/lib/libnrnoc.so /home/jovyan/neuron/nrn-7.4/x86_64/lib/liboc.so /home/jovyan/neuron/nrn-7.4/x86_64/lib/libmemacs.so /home/jovyan/neuron/nrn-7.4/x86_64/lib/libnrnmpi.so /home/jovyan/neuron/nrn-7.4/x86_64/lib/libscopmath.so /home/jovyan/neuron/nrn-7.4/x86_64/lib/libsparse13.so -lreadline -lncurses /home/jovyan/neuron/nrn-7.4/x86_64/lib/libnrniv.so /home/jovyan/neuron/nrn-7.4/x86_64/lib/libivoc.so /home/jovyan/neuron/nrn-7.4/x86_64/lib/libneuron_gnu.so /home/jovyan/neuron/nrn-7.4/x86_64/lib/libmeschach.so /home/jovyan/neuron/nrn-7.4/x86_64/lib/libsundials.so /home/jovyan/neuron/nrn-7.4/x86_64/lib/libivos.so -lm -ldl  -O2   -pthread -Wl,-soname -Wl,libnrnmech.so.0 -o .libs/libnrnmech.so.0.0.0\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > libtool: link: (cd \".libs\" && rm -f \"libnrnmech.so.0\" && ln -s \"libnrnmech.so.0.0.0\" \"libnrnmech.so.0\")\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > libtool: link: (cd \".libs\" && rm -f \"libnrnmech.so\" && ln -s \"libnrnmech.so.0.0.0\" \"libnrnmech.so\")\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > libtool: link: ( cd \".libs\" && rm -f \"libnrnmech.la\" && ln -s \"../libnrnmech.la\" \"libnrnmech.la\" )\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NMODL Compile >> > Successfully created x86_64/special\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Successful compilation\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Success: true\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Have successfully executed command: /home/jovyan/neuron/nrn-7.4/x86_64/bin/nrniv -python /tmp/vanilla_nrn.py\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Error  >>> NEURON -- Release 7.4 (1370:16a7055d4a86) 2015-11-09\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Error  >>> Duke, Yale, and the BlueBrain Project -- Copyright 1984-2015\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Error  >>> See http://www.neuron.yale.edu/neuron/credits\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Error  >>> \n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Error  >>> Additional mechanisms from files\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Error  >>>  RS.mod RS_Iext.mod\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Output >>> \n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Output >>>     Starting simulation in NEURON generated from NeuroML2 model...\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Output >>> \n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Output >>> Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Output >>> Running a simulation of 520.0ms (dt = 0.001ms)\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Output >>> Finished NEURON simulation in 0.717434 seconds (0.011957 mins)...\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Output >>> Saving results at t=519.9999999911596...\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Output >>> Saved data to: time.dat\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Output >>> Saved data to: exIzh.dat\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Output >>> Finished saving results in 1.048721 seconds\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Output >>> Done\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) NRN Output >>> first instance of n_RS_pop\n",
      "pyNeuroML >>>   jNeuroML >>  (INFO) Exit value for running NEURON: 0\n",
      "pyNeuroML >>>   jNeuroML >>  \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'v'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0440fde66911>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReducedModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLEMS_MODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vanilla'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'interesting that the basic model works'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0msuite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjudge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/sciunit/__init__.py\u001b[0m in \u001b[0;36mjudge\u001b[0;34m(self, models, skip_incapable, stop_on_error, deep_error)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 score = test.judge(model, skip_incapable=skip_incapable, \n\u001b[1;32m    429\u001b[0m                                           \u001b[0mstop_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m                                           deep_error=deep_error)\n\u001b[0m\u001b[1;32m    431\u001b[0m                 log('Score is <a style=\"color: rgb(%d,%d,%d)\">' % score.color()\n\u001b[1;32m    432\u001b[0m                   + '%s</a>' % score)\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/sciunit/__init__.py\u001b[0m in \u001b[0;36mjudge\u001b[0;34m(self, model, skip_incapable, stop_on_error, deep_error)\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mErrorScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mErrorScore\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstop_on_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;31m# An exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/sciunit/__init__.py\u001b[0m in \u001b[0;36mjudge\u001b[0;34m(self, model, skip_incapable, stop_on_error, deep_error)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_judge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_incapable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_incapable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mCapabilityError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNAScore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/sciunit/__init__.py\u001b[0m in \u001b[0;36m_judge\u001b[0;34m(self, model, skip_incapable)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_capabilities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# 2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;31m# 3.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/neuronunit/tests/__init__.py\u001b[0m in \u001b[0;36mgenerate_prediction\u001b[0;34m(self, model, verbose)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 476\u001b[0;31m         \u001b[0mlookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_FI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    477\u001b[0m         \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlookup\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0msupra\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlookup\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlookup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/neuronunit/tests/__init__.py\u001b[0m in \u001b[0;36mthreshold_FI\u001b[0;34m(self, model, units, guess, verbose)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0mmax_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m         \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mguess\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/neuronunit/tests/__init__.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(ampl)\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0mcurrent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'amplitude'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mampl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minject_square_current\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 \u001b[0mn_spikes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spike_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                     print(\"Injected %s current and got %d spikes\" % \\\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/neuronunit/capabilities/__init__.py\u001b[0m in \u001b[0;36mget_spike_count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_spike_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mspike_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spike_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspike_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/neuronunit/models/reduced.py\u001b[0m in \u001b[0;36mget_spike_train\u001b[0;34m(self, rerun, **run_params)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_spike_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrerun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrun_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_membrane_potential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrun_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mspike_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_spike_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mspike_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/neuronunit/models/reduced.py\u001b[0m in \u001b[0;36mget_membrane_potential\u001b[0;34m(self, rerun, **run_params)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mrerun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrerun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mrun_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m \u001b[0;31m# Time per sample in milliseconds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'v'"
     ]
    }
   ],
   "source": [
    "                      \n",
    "test_class_params = [(nu_tests.InputResistanceTest,None),\n",
    "                     (nu_tests.TimeConstantTest,None),\n",
    "                     (nu_tests.CapacitanceTest,None)]\n",
    "                     \n",
    "                     #,\n",
    "                     #(nu_tests.RestingPotentialTest,None),   \n",
    "                     #(nu_tests.InjectedCurrentAPWidthTest,None),\n",
    "                     #(nu_tests.InjectedCurrentAPAmplitudeTest,None),\n",
    "                     #(nu_tests.InjectedCurrentAPThresholdTest,None)]\n",
    "\n",
    "\n",
    "print('neuronunit_generated these tests')\n",
    "for cls,params in test_class_params:\n",
    "    print('neuronunit_generated these tests')\n",
    "    observation = cls.neuroelectro_summary_observation(neuron)\n",
    "    tests += [cls(observation,params=params)]\n",
    "    print(observation)\n",
    "    print(tests)\n",
    "    print(cls,params)\n",
    "\n",
    "    \n",
    "def update_amplitude(test,tests,score):\n",
    "    rheobase = score.prediction['value']\n",
    "    #for i in [3,4,5]:\n",
    "    #    tests[i].params['injected_square_current']['amplitude'] = rheobase*1.01 # Set current injection to just suprathreshold\n",
    "    \n",
    "hooks = {tests[0]:{'f':update_amplitude}}\n",
    "\n",
    "\n",
    "import pdb\n",
    "print(tests)\n",
    "print(hooks)\n",
    "print(dir(sciunit.TestSuite))\n",
    "#pdb.set_trace()\n",
    "\n",
    "\n",
    "suite = sciunit.TestSuite(\"vm_suite\",tests,hooks=hooks)\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "model = ReducedModel(LEMS_MODEL_PATH,name='vanilla')\n",
    "print('interesting that the basic model works')\n",
    "suite.judge(model)\n",
    "\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "test = nu_tests.TimeConstantTest\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "models = []\n",
    "\n",
    "\n",
    "i=0\n",
    "for vr in np.linspace(-75,-50,6):\n",
    "    model = ReducedModel(LEMS_MODEL_PATH, \n",
    "                         name='V_rest=%dmV' % vr, \n",
    "                         attrs={'//izhikevich2007Cell':\n",
    "                                    {'vr':'%d mV' % vr}\n",
    "                               })\n",
    "    #model.skip_run = True\n",
    "    i+=1\n",
    "    print('############'+'\\n')\n",
    "    print('############'+'\\n')\n",
    "    print('############'+'\\n')\n",
    "    print('############'+'\\n')\n",
    "    print('############'+'\\n')\n",
    "    print('############'+'\\n')\n",
    "    print('############'+'\\n')\n",
    "    print('############'+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "    print(vr,' failed for this parameter')\n",
    "    print(i,' failed for this index')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('############'+'\\n')\n",
    "    print('############'+'\\n')\n",
    "    print('############'+'\\n')\n",
    "    print('############'+'\\n')\n",
    "    print('############'+'\\n')\n",
    "    print('############'+'\\n')\n",
    "\n",
    "\n",
    "\n",
    "    models.append(model)\n",
    "\n",
    "    #pdb.set_trace() \n",
    "    check_error = suite.judge(model)\n",
    "  \n",
    "print('interesting that judging a list of models with different parameters does not work. Where does it fail?')\n",
    "print('surely its just the nans or someother weird data type causing a value that is not optimizible in a data range')\n",
    "print('it would be easier to evaluate if each model was optomized inside the loop')\n",
    "score_matrix = suite.judge(models)\n",
    "score_matrix.show_mean = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
